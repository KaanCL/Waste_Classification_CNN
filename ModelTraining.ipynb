{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1|ImportÄ±ng Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import warnings\n",
    "import splitfolders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2|EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootPath = \"dataset/garbage_images\"\n",
    "class_names = os.listdir(rootPath)\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = [len(os.listdir(os.path.join(rootPath, class_name))) for class_name in class_names]\n",
    "\n",
    "fig = px.pie(\n",
    "    names=class_names,\n",
    "    values=sizes,\n",
    "    title=\"Garbage Image Dataset Distribution\",\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nðŸ“ DATASET STRUCTURE:\")\n",
    "print(f\"Total number of categories: {len(class_names)}\")\n",
    "print(f\"Categories: {class_names}\")\n",
    "\n",
    "category_data = []\n",
    "total_images = 0\n",
    "\n",
    "for class_name in class_names:\n",
    "    class_path = os.path.join(rootPath, class_name)\n",
    "    if os.path.isdir(class_path):\n",
    "   \n",
    "        image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.gif', '.tiff']\n",
    "        image_files = [f for f in os.listdir(class_path) \n",
    "                      if any(f.lower().endswith(ext) for ext in image_extensions)]\n",
    "        count = len(image_files)\n",
    "        total_images += count\n",
    "        category_data.append({\n",
    "            'Category': class_name,\n",
    "            'Count': count,\n",
    "            'Percentage': 0  \n",
    "        })\n",
    "\n",
    "for item in category_data:\n",
    "    item['Percentage'] = (item['Count'] / total_images) * 100\n",
    "\n",
    "df = pd.DataFrame(category_data)\n",
    "df = df.sort_values('Count', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nTotal number of images: {total_images}\")\n",
    "print(\"\\nðŸ“Š CATEGORY DISTRIBUTION:\")\n",
    "print(df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3|Data Spliting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undersample_class (class_dir,target_count = 400 , output_dir = None):\n",
    "    images = os.listdir(class_dir)\n",
    "    if len(images)>target_count:\n",
    "        selected = random.sample(images, target_count)\n",
    "    else:\n",
    "        selected = images\n",
    "    \n",
    "    if output_dir:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        for img in selected:\n",
    "            shutil.copy(os.path.join(class_dir, img), os.path.join(output_dir, img))\n",
    "    return selected\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'  \n",
    ")\n",
    "\n",
    "def augment_images(class_dir, target_count=400, output_dir=None):\n",
    "    images = os.listdir(class_dir)\n",
    "    current_count = len(images)\n",
    "\n",
    "    if current_count >= target_count:\n",
    "        print(f\"Already have {current_count} images in {class_dir}, no augmentation needed.\")\n",
    "        return\n",
    "\n",
    "    if output_dir is None:\n",
    "        output_dir = class_dir\n",
    "\n",
    "    if class_dir != output_dir:\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        for img in images:\n",
    "            src = os.path.join(class_dir, img)\n",
    "            dst = os.path.join(output_dir, img)\n",
    "            if not os.path.exists(dst):\n",
    "                shutil.copy(src, dst)\n",
    "\n",
    "    images = os.listdir(output_dir)  \n",
    "    current_count = len(images)\n",
    "    i = 0\n",
    "\n",
    "    while current_count + i < target_count:\n",
    "        img_name = np.random.choice(images)\n",
    "        path = os.path.join(output_dir, img_name)  \n",
    "        img = Image.open(path).convert('RGB')\n",
    "        x = np.array(img)\n",
    "        x = x.reshape((1,) + x.shape)\n",
    "\n",
    "        for batch in datagen.flow(x,                            \n",
    "                                  batch_size=32,\n",
    "                                  save_to_dir=output_dir,\n",
    "                                  save_prefix='aug',\n",
    "                                  save_format='jpeg'):\n",
    "            i += 1\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_dir = \"dataset/balanced_waste_images\"\n",
    "\n",
    "for cls in class_names:\n",
    "    class_path = os.path.join(rootPath, cls)\n",
    "    output_class_path = os.path.join(balanced_dir, cls)\n",
    "    os.makedirs(output_class_path, exist_ok=True)\n",
    "\n",
    "    images = os.listdir(class_path)\n",
    "    count = len(images)\n",
    "\n",
    "    if count > 400:\n",
    "        undersample_class(class_path, 400, output_dir=output_class_path)\n",
    "    else:\n",
    "        for img in images:\n",
    "            print(f\"Copying {img} to {output_class_path}\")\n",
    "            shutil.copy(os.path.join(class_path, img), os.path.join(output_class_path, img))\n",
    "\n",
    "        augment_images(output_class_path, 400, output_class_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = [len(os.listdir(os.path.join(\"dataset/balanced_waste_images\", class_name))) for class_name in class_names]\n",
    "\n",
    "rootPath = \"dataset/balanced_waste_images\"\n",
    "class_names = os.listdir(rootPath)\n",
    "\n",
    "fig = px.pie(\n",
    "    names=class_names,\n",
    "    values=sizes,\n",
    "    title=\"Garbage Image Dataset Distribution\",\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitfolders.ratio(input=rootPath,output='imgs',seed=15,ratio=(.8,.1,.1),group_prefix=None,move=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'imgs/train'\n",
    "val_dir = 'imgs/val'\n",
    "test_dir = 'imgs/test'\n",
    "\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "CLASSES_NUM = 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_gen = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_gen = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_gen= test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4|CNN MODEL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = MobileNetV2(\n",
    "    input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "base_model.trainable = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "predictions = Dense(CLASSES_NUM, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=10  \n",
    ")\n",
    "\n",
    "model.save(\"WasteClassification_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
